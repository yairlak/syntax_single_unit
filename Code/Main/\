from functions import load_settings_params, read_logs_and_features, convert_to_mne, data_manip, analyses
import argparse, os, sys, pickle
abspath = os.path.abspath(__file__)
dname = os.path.dirname(abspath)
os.chdir(dname)
sys.path.append('..')
import mne
from mne.decoding import (cross_val_multiscore, LinearModel, GeneralizingEstimator)
from functions import classification, comparisons, load_settings_params
from functions.utils import dict2filename, update_queries, probename2picks, pick_responsive_channels
from sklearn.pipeline import make_pipeline
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.multiclass import OneVsRestClassifier
from sklearn.manifold import MDS
from sklearn.model_selection import ShuffleSplit
from sklearn.cluster import AgglomerativeClustering
from skorch import NeuralNetClassifier
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.utils.class_weight import compute_class_weight
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.svm import LinearSVC
from scipy import stats
from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import dendrogram
from sklearn.manifold import TSNE
import numpy as np
import matplotlib.pyplot as plt
from pprint import pprint
import torch
import models # custom module with neural-network models (LSTM/GRU/CNN)


parser = argparse.ArgumentParser(description='Generate plots for TIMIT experiment')
# QUERY
parser.add_argument('--dimension', default='word_string', help='Comparison name from Code/Main/functions/comparisons.py')
parser.add_argument('--comparison-name', default='word_string', help='Comparison name from Code/Main/functions/comparisons.py')
parser.add_argument('--pick-classes', default=[], type=str, nargs='*', help='Limit the classes to this list')
# PARSE
args = parser.parse_args()

########
# INIT #
########
# GET METADATA BY READING THE LOGS FROM THE FOLLOWING PATIENT:
patient = 'patient_479_11'
print('Loading settings, params and preferences...')
settings = load_settings_params.Settings(patient)
params = load_settings_params.Params(patient)
preferences = load_settings_params.Preferences()

print('Metadata: Loading features and comparisons from Excel files...')
features = read_logs_and_features.load_features(settings)

print('Logs: Reading experiment log files from experiment...')
log_all_blocks = {}
for block in range(1, 7):
    log = read_logs_and_features.read_log(block, settings)
    log_all_blocks[block] = log

print('Loading POS tags for all words in the lexicon')
word2pos = read_logs_and_features.load_POS_tags(settings)

print('Preparing meta-data')
metadata = read_logs_and_features.prepare_metadata(log_all_blocks, features, word2pos, settings, params, preferences)




#################
# GENERATE DSM  #
#################
classes = list(set(metadata[args.dimension]))
num_classes = len(classes)
if args.dimension == 'word_string':
    for i_class in range(num_classes):
        for j_class range(i_class + 1, num_classes):
            c_i, c_j = classes(i_class), classes(j_class)
            letters_c_i, letters_c_j = set(list(c_i)), set(list(c_j))
            num_shared_letters = len(letters_c_i & letters_c_j)
            print(c_i, c_j, num_shared_letters)
        

####################
# SAVE DSM TO FILE #
####################
# Which args to have in fig filename
list_args2fname = ['patient', 'data_type', 'filter', 'level', 'comparison_name', 'block_type', 'time_window', 'num_bins', 'min_trials']
print('args2fname', list_args2fname)
args2fname = args.__dict__.copy()
if len(list(set(args2fname['data_type']))) == 1: args2fname['data_type'] = list(set(args2fname['data_type']))
if len(list(set(args2fname['filter']))) == 1: args2fname['filter'] = list(set(args2fname['filter']))
args2fname['probe_name'] = sorted(list(set([item for sublist in args2fname['probe_name'] for item in sublist]))) # !! lump together all probe names !! to reduce filename length
if 'time' not in list_args2fname: list_args2fname.append('time')
args2fname['time'] = t

fname_conf = dict2filename(args2fname, '_', list_args2fname, 'pkl', True)
fname_conf = os.path.join(args.path2output, 'DSM_' + args.model_type + '_' + fname_conf)
with open(fname_conf, 'wb') as f:
    pickle.dump([DSM, comparison, args, classes, labels], f)


